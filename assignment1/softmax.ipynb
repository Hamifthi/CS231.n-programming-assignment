{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.396069\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -5.133627 analytic: -5.133627, relative error: 7.785956e-09\n",
      "numerical: -2.085453 analytic: -2.085453, relative error: 8.203348e-09\n",
      "numerical: 3.291466 analytic: 3.291466, relative error: 1.652272e-08\n",
      "numerical: -2.175768 analytic: -2.175768, relative error: 1.004843e-08\n",
      "numerical: -1.814155 analytic: -1.814155, relative error: 1.182503e-08\n",
      "numerical: -1.155703 analytic: -1.155704, relative error: 1.681517e-08\n",
      "numerical: -1.086227 analytic: -1.086227, relative error: 1.122148e-08\n",
      "numerical: 2.008707 analytic: 2.008707, relative error: 1.334869e-08\n",
      "numerical: 1.778756 analytic: 1.778756, relative error: 1.345035e-08\n",
      "numerical: 1.008365 analytic: 1.008365, relative error: 2.778457e-09\n",
      "numerical: -2.693824 analytic: -2.693825, relative error: 3.410307e-08\n",
      "numerical: -0.285075 analytic: -0.285075, relative error: 8.950879e-08\n",
      "numerical: -1.418676 analytic: -1.418677, relative error: 2.567463e-08\n",
      "numerical: 0.069723 analytic: 0.069723, relative error: 1.762237e-07\n",
      "numerical: -1.207169 analytic: -1.207169, relative error: 1.991182e-08\n",
      "numerical: -0.329197 analytic: -0.329197, relative error: 3.740695e-08\n",
      "numerical: -0.096381 analytic: -0.096381, relative error: 3.955507e-07\n",
      "numerical: -0.144583 analytic: -0.144583, relative error: 2.455122e-07\n",
      "numerical: -0.080049 analytic: -0.080049, relative error: 7.120769e-08\n",
      "numerical: -0.742737 analytic: -0.742737, relative error: 8.782433e-09\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.396069e+00 computed in 0.242836s\n",
      "vectorized loss: 2.396069e+00 computed in 0.015628s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 769.359338\n",
      "iteration 100 / 1500: loss 282.566804\n",
      "iteration 200 / 1500: loss 104.572505\n",
      "iteration 300 / 1500: loss 39.648791\n",
      "iteration 400 / 1500: loss 15.826127\n",
      "iteration 500 / 1500: loss 7.170118\n",
      "iteration 600 / 1500: loss 3.998715\n",
      "iteration 700 / 1500: loss 2.781121\n",
      "iteration 800 / 1500: loss 2.296986\n",
      "iteration 900 / 1500: loss 2.166015\n",
      "iteration 1000 / 1500: loss 2.109780\n",
      "iteration 1100 / 1500: loss 2.075426\n",
      "iteration 1200 / 1500: loss 2.111577\n",
      "iteration 1300 / 1500: loss 2.107450\n",
      "iteration 1400 / 1500: loss 2.116039\n",
      "iteration 0 / 1500: loss 962.095777\n",
      "iteration 100 / 1500: loss 275.112648\n",
      "iteration 200 / 1500: loss 79.762656\n",
      "iteration 300 / 1500: loss 24.206259\n",
      "iteration 400 / 1500: loss 8.335650\n",
      "iteration 500 / 1500: loss 3.906808\n",
      "iteration 600 / 1500: loss 2.574428\n",
      "iteration 700 / 1500: loss 2.261686\n",
      "iteration 800 / 1500: loss 2.186856\n",
      "iteration 900 / 1500: loss 2.116158\n",
      "iteration 1000 / 1500: loss 2.110579\n",
      "iteration 1100 / 1500: loss 2.059589\n",
      "iteration 1200 / 1500: loss 2.135478\n",
      "iteration 1300 / 1500: loss 2.115435\n",
      "iteration 1400 / 1500: loss 2.133772\n",
      "iteration 0 / 1500: loss 1171.571488\n",
      "iteration 100 / 1500: loss 260.431487\n",
      "iteration 200 / 1500: loss 59.193003\n",
      "iteration 300 / 1500: loss 14.773116\n",
      "iteration 400 / 1500: loss 4.911903\n",
      "iteration 500 / 1500: loss 2.699678\n",
      "iteration 600 / 1500: loss 2.192894\n",
      "iteration 700 / 1500: loss 2.192977\n",
      "iteration 800 / 1500: loss 2.127518\n",
      "iteration 900 / 1500: loss 2.154678\n",
      "iteration 1000 / 1500: loss 2.094027\n",
      "iteration 1100 / 1500: loss 2.093394\n",
      "iteration 1200 / 1500: loss 2.127937\n",
      "iteration 1300 / 1500: loss 2.120217\n",
      "iteration 1400 / 1500: loss 2.172980\n",
      "iteration 0 / 1500: loss 1332.989259\n",
      "iteration 100 / 1500: loss 230.806035\n",
      "iteration 200 / 1500: loss 41.452324\n",
      "iteration 300 / 1500: loss 8.942100\n",
      "iteration 400 / 1500: loss 3.330514\n",
      "iteration 500 / 1500: loss 2.394279\n",
      "iteration 600 / 1500: loss 2.174752\n",
      "iteration 700 / 1500: loss 2.101133\n",
      "iteration 800 / 1500: loss 2.170378\n",
      "iteration 900 / 1500: loss 2.158273\n",
      "iteration 1000 / 1500: loss 2.173158\n",
      "iteration 1100 / 1500: loss 2.137259\n",
      "iteration 1200 / 1500: loss 2.129799\n",
      "iteration 1300 / 1500: loss 2.168239\n",
      "iteration 1400 / 1500: loss 2.137775\n",
      "iteration 0 / 1500: loss 1550.514146\n",
      "iteration 100 / 1500: loss 208.799623\n",
      "iteration 200 / 1500: loss 29.725279\n",
      "iteration 300 / 1500: loss 5.831233\n",
      "iteration 400 / 1500: loss 2.616495\n",
      "iteration 500 / 1500: loss 2.190658\n",
      "iteration 600 / 1500: loss 2.140893\n",
      "iteration 700 / 1500: loss 2.167281\n",
      "iteration 800 / 1500: loss 2.191774\n",
      "iteration 900 / 1500: loss 2.160067\n",
      "iteration 1000 / 1500: loss 2.154573\n",
      "iteration 1100 / 1500: loss 2.170036\n",
      "iteration 1200 / 1500: loss 2.141364\n",
      "iteration 1300 / 1500: loss 2.150167\n",
      "iteration 1400 / 1500: loss 2.100199\n",
      "iteration 0 / 1500: loss 768.420221\n",
      "iteration 100 / 1500: loss 103.951059\n",
      "iteration 200 / 1500: loss 15.746743\n",
      "iteration 300 / 1500: loss 3.959659\n",
      "iteration 400 / 1500: loss 2.285399\n",
      "iteration 500 / 1500: loss 2.124488\n",
      "iteration 600 / 1500: loss 2.048015\n",
      "iteration 700 / 1500: loss 2.056869\n",
      "iteration 800 / 1500: loss 2.059694\n",
      "iteration 900 / 1500: loss 2.079757\n",
      "iteration 1000 / 1500: loss 2.068558\n",
      "iteration 1100 / 1500: loss 2.075545\n",
      "iteration 1200 / 1500: loss 2.098393\n",
      "iteration 1300 / 1500: loss 2.108150\n",
      "iteration 1400 / 1500: loss 2.092717\n",
      "iteration 0 / 1500: loss 960.407712\n",
      "iteration 100 / 1500: loss 79.039365\n",
      "iteration 200 / 1500: loss 8.278191\n",
      "iteration 300 / 1500: loss 2.594871\n",
      "iteration 400 / 1500: loss 2.109808\n",
      "iteration 500 / 1500: loss 2.114012\n",
      "iteration 600 / 1500: loss 2.066611\n",
      "iteration 700 / 1500: loss 2.054774\n",
      "iteration 800 / 1500: loss 2.122578\n",
      "iteration 900 / 1500: loss 2.110067\n",
      "iteration 1000 / 1500: loss 2.083758\n",
      "iteration 1100 / 1500: loss 2.091687\n",
      "iteration 1200 / 1500: loss 2.168920\n",
      "iteration 1300 / 1500: loss 2.182347\n",
      "iteration 1400 / 1500: loss 2.087651\n",
      "iteration 0 / 1500: loss 1158.837847\n",
      "iteration 100 / 1500: loss 57.993166\n",
      "iteration 200 / 1500: loss 4.831626\n",
      "iteration 300 / 1500: loss 2.275610\n",
      "iteration 400 / 1500: loss 2.142396\n",
      "iteration 500 / 1500: loss 2.122146\n",
      "iteration 600 / 1500: loss 2.150797\n",
      "iteration 700 / 1500: loss 2.110186\n",
      "iteration 800 / 1500: loss 2.140245\n",
      "iteration 900 / 1500: loss 2.139595\n",
      "iteration 1000 / 1500: loss 2.115317\n",
      "iteration 1100 / 1500: loss 2.138195\n",
      "iteration 1200 / 1500: loss 2.178822\n",
      "iteration 1300 / 1500: loss 2.122517\n",
      "iteration 1400 / 1500: loss 2.118125\n",
      "iteration 0 / 1500: loss 1345.180244\n",
      "iteration 100 / 1500: loss 41.190299\n",
      "iteration 200 / 1500: loss 3.260380\n",
      "iteration 300 / 1500: loss 2.203841\n",
      "iteration 400 / 1500: loss 2.169629\n",
      "iteration 500 / 1500: loss 2.128761\n",
      "iteration 600 / 1500: loss 2.115651\n",
      "iteration 700 / 1500: loss 2.176825\n",
      "iteration 800 / 1500: loss 2.112067\n",
      "iteration 900 / 1500: loss 2.130206\n",
      "iteration 1000 / 1500: loss 2.121497\n",
      "iteration 1100 / 1500: loss 2.164955\n",
      "iteration 1200 / 1500: loss 2.150022\n",
      "iteration 1300 / 1500: loss 2.111957\n",
      "iteration 1400 / 1500: loss 2.178083\n",
      "iteration 0 / 1500: loss 1553.523854\n",
      "iteration 100 / 1500: loss 29.255941\n",
      "iteration 200 / 1500: loss 2.625946\n",
      "iteration 300 / 1500: loss 2.130797\n",
      "iteration 400 / 1500: loss 2.105198\n",
      "iteration 500 / 1500: loss 2.166228\n",
      "iteration 600 / 1500: loss 2.164286\n",
      "iteration 700 / 1500: loss 2.089648\n",
      "iteration 800 / 1500: loss 2.081694\n",
      "iteration 900 / 1500: loss 2.171929\n",
      "iteration 1000 / 1500: loss 2.134353\n",
      "iteration 1100 / 1500: loss 2.097632\n",
      "iteration 1200 / 1500: loss 2.179672\n",
      "iteration 1300 / 1500: loss 2.080262\n",
      "iteration 1400 / 1500: loss 2.134841\n",
      "iteration 0 / 1500: loss 772.950673\n",
      "iteration 100 / 1500: loss 39.170191\n",
      "iteration 200 / 1500: loss 3.889497\n",
      "iteration 300 / 1500: loss 2.221023\n",
      "iteration 400 / 1500: loss 2.078349\n",
      "iteration 500 / 1500: loss 2.062075\n",
      "iteration 600 / 1500: loss 2.059817\n",
      "iteration 700 / 1500: loss 2.056319\n",
      "iteration 800 / 1500: loss 2.034822\n",
      "iteration 900 / 1500: loss 2.108412\n",
      "iteration 1000 / 1500: loss 2.080683\n",
      "iteration 1100 / 1500: loss 2.086264\n",
      "iteration 1200 / 1500: loss 2.067063\n",
      "iteration 1300 / 1500: loss 2.054613\n",
      "iteration 1400 / 1500: loss 2.106908\n",
      "iteration 0 / 1500: loss 971.504986\n",
      "iteration 100 / 1500: loss 23.900141\n",
      "iteration 200 / 1500: loss 2.605539\n",
      "iteration 300 / 1500: loss 2.048338\n",
      "iteration 400 / 1500: loss 2.047251\n",
      "iteration 500 / 1500: loss 2.085752\n",
      "iteration 600 / 1500: loss 2.109010\n",
      "iteration 700 / 1500: loss 2.116150\n",
      "iteration 800 / 1500: loss 2.122335\n",
      "iteration 900 / 1500: loss 2.136256\n",
      "iteration 1000 / 1500: loss 2.101935\n",
      "iteration 1100 / 1500: loss 2.081128\n",
      "iteration 1200 / 1500: loss 2.145969\n",
      "iteration 1300 / 1500: loss 2.104864\n",
      "iteration 1400 / 1500: loss 2.124139\n",
      "iteration 0 / 1500: loss 1167.547104\n",
      "iteration 100 / 1500: loss 14.293032\n",
      "iteration 200 / 1500: loss 2.275622\n",
      "iteration 300 / 1500: loss 2.139753\n",
      "iteration 400 / 1500: loss 2.105414\n",
      "iteration 500 / 1500: loss 2.106610\n",
      "iteration 600 / 1500: loss 2.082657\n",
      "iteration 700 / 1500: loss 2.116741\n",
      "iteration 800 / 1500: loss 2.117685\n",
      "iteration 900 / 1500: loss 2.090675\n",
      "iteration 1000 / 1500: loss 2.146321\n",
      "iteration 1100 / 1500: loss 2.100213\n",
      "iteration 1200 / 1500: loss 2.053538\n",
      "iteration 1300 / 1500: loss 2.132892\n",
      "iteration 1400 / 1500: loss 2.158691\n",
      "iteration 0 / 1500: loss 1342.027168\n",
      "iteration 100 / 1500: loss 8.637645\n",
      "iteration 200 / 1500: loss 2.195658\n",
      "iteration 300 / 1500: loss 2.138254\n",
      "iteration 400 / 1500: loss 2.111519\n",
      "iteration 500 / 1500: loss 2.152387\n",
      "iteration 600 / 1500: loss 2.139137\n",
      "iteration 700 / 1500: loss 2.138718\n",
      "iteration 800 / 1500: loss 2.135686\n",
      "iteration 900 / 1500: loss 2.138680\n",
      "iteration 1000 / 1500: loss 2.160602\n",
      "iteration 1100 / 1500: loss 2.194314\n",
      "iteration 1200 / 1500: loss 2.132911\n",
      "iteration 1300 / 1500: loss 2.132189\n",
      "iteration 1400 / 1500: loss 2.107542\n",
      "iteration 0 / 1500: loss 1520.399803\n",
      "iteration 100 / 1500: loss 5.523939\n",
      "iteration 200 / 1500: loss 2.158904\n",
      "iteration 300 / 1500: loss 2.165723\n",
      "iteration 400 / 1500: loss 2.190370\n",
      "iteration 500 / 1500: loss 2.110570\n",
      "iteration 600 / 1500: loss 2.170578\n",
      "iteration 700 / 1500: loss 2.168769\n",
      "iteration 800 / 1500: loss 2.132392\n",
      "iteration 900 / 1500: loss 2.158937\n",
      "iteration 1000 / 1500: loss 2.137682\n",
      "iteration 1100 / 1500: loss 2.170000\n",
      "iteration 1200 / 1500: loss 2.157446\n",
      "iteration 1300 / 1500: loss 2.169702\n",
      "iteration 1400 / 1500: loss 2.167986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 776.482064\n",
      "iteration 100 / 1500: loss 15.560946\n",
      "iteration 200 / 1500: loss 2.321088\n",
      "iteration 300 / 1500: loss 2.012730\n",
      "iteration 400 / 1500: loss 2.064371\n",
      "iteration 500 / 1500: loss 2.098173\n",
      "iteration 600 / 1500: loss 2.072344\n",
      "iteration 700 / 1500: loss 2.094397\n",
      "iteration 800 / 1500: loss 2.069686\n",
      "iteration 900 / 1500: loss 2.102617\n",
      "iteration 1000 / 1500: loss 2.084443\n",
      "iteration 1100 / 1500: loss 2.046538\n",
      "iteration 1200 / 1500: loss 2.080031\n",
      "iteration 1300 / 1500: loss 2.096989\n",
      "iteration 1400 / 1500: loss 2.063868\n",
      "iteration 0 / 1500: loss 963.559450\n",
      "iteration 100 / 1500: loss 8.090688\n",
      "iteration 200 / 1500: loss 2.129262\n",
      "iteration 300 / 1500: loss 2.137248\n",
      "iteration 400 / 1500: loss 2.152892\n",
      "iteration 500 / 1500: loss 2.149567\n",
      "iteration 600 / 1500: loss 2.035029\n",
      "iteration 700 / 1500: loss 2.125184\n",
      "iteration 800 / 1500: loss 2.118516\n",
      "iteration 900 / 1500: loss 2.129659\n",
      "iteration 1000 / 1500: loss 2.120754\n",
      "iteration 1100 / 1500: loss 2.127183\n",
      "iteration 1200 / 1500: loss 2.075714\n",
      "iteration 1300 / 1500: loss 2.182430\n",
      "iteration 1400 / 1500: loss 2.081943\n",
      "iteration 0 / 1500: loss 1148.744022\n",
      "iteration 100 / 1500: loss 4.645450\n",
      "iteration 200 / 1500: loss 2.170682\n",
      "iteration 300 / 1500: loss 2.130911\n",
      "iteration 400 / 1500: loss 2.099145\n",
      "iteration 500 / 1500: loss 2.145696\n",
      "iteration 600 / 1500: loss 2.118787\n",
      "iteration 700 / 1500: loss 2.074743\n",
      "iteration 800 / 1500: loss 2.137175\n",
      "iteration 900 / 1500: loss 2.150083\n",
      "iteration 1000 / 1500: loss 2.159048\n",
      "iteration 1100 / 1500: loss 2.135792\n",
      "iteration 1200 / 1500: loss 2.123221\n",
      "iteration 1300 / 1500: loss 2.111984\n",
      "iteration 1400 / 1500: loss 2.146046\n",
      "iteration 0 / 1500: loss 1365.165345\n",
      "iteration 100 / 1500: loss 3.233086\n",
      "iteration 200 / 1500: loss 2.075719\n",
      "iteration 300 / 1500: loss 2.149083\n",
      "iteration 400 / 1500: loss 2.117721\n",
      "iteration 500 / 1500: loss 2.127412\n",
      "iteration 600 / 1500: loss 2.148667\n",
      "iteration 700 / 1500: loss 2.094033\n",
      "iteration 800 / 1500: loss 2.130762\n",
      "iteration 900 / 1500: loss 2.152003\n",
      "iteration 1000 / 1500: loss 2.082818\n",
      "iteration 1100 / 1500: loss 2.117721\n",
      "iteration 1200 / 1500: loss 2.158964\n",
      "iteration 1300 / 1500: loss 2.137611\n",
      "iteration 1400 / 1500: loss 2.130845\n",
      "iteration 0 / 1500: loss 1536.538330\n",
      "iteration 100 / 1500: loss 2.558882\n",
      "iteration 200 / 1500: loss 2.160387\n",
      "iteration 300 / 1500: loss 2.160299\n",
      "iteration 400 / 1500: loss 2.192233\n",
      "iteration 500 / 1500: loss 2.195978\n",
      "iteration 600 / 1500: loss 2.116315\n",
      "iteration 700 / 1500: loss 2.180043\n",
      "iteration 800 / 1500: loss 2.115146\n",
      "iteration 900 / 1500: loss 2.116808\n",
      "iteration 1000 / 1500: loss 2.188068\n",
      "iteration 1100 / 1500: loss 2.145470\n",
      "iteration 1200 / 1500: loss 2.145706\n",
      "iteration 1300 / 1500: loss 2.144875\n",
      "iteration 1400 / 1500: loss 2.189254\n",
      "iteration 0 / 1500: loss 785.308840\n",
      "iteration 100 / 1500: loss 6.954775\n",
      "iteration 200 / 1500: loss 2.134161\n",
      "iteration 300 / 1500: loss 2.030325\n",
      "iteration 400 / 1500: loss 2.055387\n",
      "iteration 500 / 1500: loss 2.053666\n",
      "iteration 600 / 1500: loss 2.089366\n",
      "iteration 700 / 1500: loss 2.029485\n",
      "iteration 800 / 1500: loss 2.103667\n",
      "iteration 900 / 1500: loss 2.091716\n",
      "iteration 1000 / 1500: loss 2.164053\n",
      "iteration 1100 / 1500: loss 2.064719\n",
      "iteration 1200 / 1500: loss 2.119301\n",
      "iteration 1300 / 1500: loss 2.079199\n",
      "iteration 1400 / 1500: loss 2.098778\n",
      "iteration 0 / 1500: loss 972.102649\n",
      "iteration 100 / 1500: loss 3.777845\n",
      "iteration 200 / 1500: loss 2.161144\n",
      "iteration 300 / 1500: loss 2.035968\n",
      "iteration 400 / 1500: loss 2.118169\n",
      "iteration 500 / 1500: loss 2.066400\n",
      "iteration 600 / 1500: loss 2.084914\n",
      "iteration 700 / 1500: loss 2.060733\n",
      "iteration 800 / 1500: loss 2.133270\n",
      "iteration 900 / 1500: loss 2.071397\n",
      "iteration 1000 / 1500: loss 2.063580\n",
      "iteration 1100 / 1500: loss 2.072979\n",
      "iteration 1200 / 1500: loss 2.119022\n",
      "iteration 1300 / 1500: loss 2.121147\n",
      "iteration 1400 / 1500: loss 2.075259\n",
      "iteration 0 / 1500: loss 1142.314656\n",
      "iteration 100 / 1500: loss 2.700331\n",
      "iteration 200 / 1500: loss 2.119948\n",
      "iteration 300 / 1500: loss 2.150560\n",
      "iteration 400 / 1500: loss 2.107337\n",
      "iteration 500 / 1500: loss 2.119499\n",
      "iteration 600 / 1500: loss 2.118791\n",
      "iteration 700 / 1500: loss 2.131239\n",
      "iteration 800 / 1500: loss 2.131002\n",
      "iteration 900 / 1500: loss 2.107574\n",
      "iteration 1000 / 1500: loss 2.124827\n",
      "iteration 1100 / 1500: loss 2.119203\n",
      "iteration 1200 / 1500: loss 2.141436\n",
      "iteration 1300 / 1500: loss 2.149222\n",
      "iteration 1400 / 1500: loss 2.114353\n",
      "iteration 0 / 1500: loss 1340.966493\n",
      "iteration 100 / 1500: loss 2.268908\n",
      "iteration 200 / 1500: loss 2.136931\n",
      "iteration 300 / 1500: loss 2.153809\n",
      "iteration 400 / 1500: loss 2.159412\n",
      "iteration 500 / 1500: loss 2.131243\n",
      "iteration 600 / 1500: loss 2.102529\n",
      "iteration 700 / 1500: loss 2.152234\n",
      "iteration 800 / 1500: loss 2.152098\n",
      "iteration 900 / 1500: loss 2.169298\n",
      "iteration 1000 / 1500: loss 2.175006\n",
      "iteration 1100 / 1500: loss 2.149274\n",
      "iteration 1200 / 1500: loss 2.094888\n",
      "iteration 1300 / 1500: loss 2.088682\n",
      "iteration 1400 / 1500: loss 2.151234\n",
      "iteration 0 / 1500: loss 1537.702487\n",
      "iteration 100 / 1500: loss 2.198393\n",
      "iteration 200 / 1500: loss 2.146695\n",
      "iteration 300 / 1500: loss 2.199085\n",
      "iteration 400 / 1500: loss 2.129186\n",
      "iteration 500 / 1500: loss 2.161042\n",
      "iteration 600 / 1500: loss 2.192655\n",
      "iteration 700 / 1500: loss 2.179712\n",
      "iteration 800 / 1500: loss 2.149514\n",
      "iteration 900 / 1500: loss 2.091368\n",
      "iteration 1000 / 1500: loss 2.171710\n",
      "iteration 1100 / 1500: loss 2.146481\n",
      "iteration 1200 / 1500: loss 2.118228\n",
      "iteration 1300 / 1500: loss 2.140055\n",
      "iteration 1400 / 1500: loss 2.143725\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.326469 val accuracy: 0.341000\n",
      "lr 1.000000e-07 reg 3.125000e+04 train accuracy: 0.325959 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 3.750000e+04 train accuracy: 0.322143 val accuracy: 0.333000\n",
      "lr 1.000000e-07 reg 4.375000e+04 train accuracy: 0.306857 val accuracy: 0.322000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.305510 val accuracy: 0.321000\n",
      "lr 2.000000e-07 reg 2.500000e+04 train accuracy: 0.328673 val accuracy: 0.347000\n",
      "lr 2.000000e-07 reg 3.125000e+04 train accuracy: 0.327020 val accuracy: 0.335000\n",
      "lr 2.000000e-07 reg 3.750000e+04 train accuracy: 0.318510 val accuracy: 0.334000\n",
      "lr 2.000000e-07 reg 4.375000e+04 train accuracy: 0.299490 val accuracy: 0.316000\n",
      "lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.310429 val accuracy: 0.318000\n",
      "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.328429 val accuracy: 0.348000\n",
      "lr 3.000000e-07 reg 3.125000e+04 train accuracy: 0.318347 val accuracy: 0.328000\n",
      "lr 3.000000e-07 reg 3.750000e+04 train accuracy: 0.318878 val accuracy: 0.335000\n",
      "lr 3.000000e-07 reg 4.375000e+04 train accuracy: 0.318082 val accuracy: 0.325000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.307204 val accuracy: 0.313000\n",
      "lr 4.000000e-07 reg 2.500000e+04 train accuracy: 0.325653 val accuracy: 0.341000\n",
      "lr 4.000000e-07 reg 3.125000e+04 train accuracy: 0.328347 val accuracy: 0.337000\n",
      "lr 4.000000e-07 reg 3.750000e+04 train accuracy: 0.307388 val accuracy: 0.330000\n",
      "lr 4.000000e-07 reg 4.375000e+04 train accuracy: 0.306122 val accuracy: 0.318000\n",
      "lr 4.000000e-07 reg 5.000000e+04 train accuracy: 0.293571 val accuracy: 0.309000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.314939 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 3.125000e+04 train accuracy: 0.312102 val accuracy: 0.326000\n",
      "lr 5.000000e-07 reg 3.750000e+04 train accuracy: 0.320633 val accuracy: 0.330000\n",
      "lr 5.000000e-07 reg 4.375000e+04 train accuracy: 0.304122 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.307510 val accuracy: 0.319000\n",
      "best validation accuracy achieved during cross-validation: 0.348000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the classifier; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for lr in np.linspace(1e-7, 5e-7, 5):\n",
    "    for reg in np.linspace(2.5e4, 5e4, 5):\n",
    "        classifier = Softmax()\n",
    "        classifier.train(X_train, y_train, learning_rate = lr, reg = reg,\n",
    "                      num_iters = 1500, verbose = True)\n",
    "        training_accuracy = np.mean(classifier.predict(X_train) == y_train)\n",
    "        validation_accuracy = np.mean(classifier.predict(X_val) == y_val)\n",
    "        results[lr, reg] = [training_accuracy, validation_accuracy]\n",
    "        if validation_accuracy > best_val:\n",
    "            best_val = validation_accuracy\n",
    "            best_classifier = classifier\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.342000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "best_softmax = best_classifier\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21f8ccf2710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
